{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we focus on the problem of validating the input data fed to ML pipelines. The importance of this problem is hard to overstate, especially for production pipelines. Irrespective of the ML algorithms used, data errors can adversely affect the quality of the generated model. Therefore, it is imperative to catch data errors early. The importance of error-free data also applies to the task of model understanding, since any attempt to debug and understand the output of the model must be grounded on the assumption that the data is adequately clean. All these observations point to the fact that we need to elevate data to a first-class citizen in ML pipelines, on par with algorithms and infrastructure, with corresponding tooling to continuously monitor and validate data throughout the various stages of the pipeline.\n",
    "\n",
    "There are many reasons to analyze and transform your data:\n",
    "\n",
    "* To find problems in your data. Common problems include:\n",
    "    * Missing data, such as features with empty values.\n",
    "    * Labels treated as features, so that your model gets to peek at the right answer during training.\n",
    "    * Features with values outside the range you expect.\n",
    "    * Missing or unexpected features.\n",
    "    * Feature with not enough proportion of the examples.\n",
    "    * Unexpected feature type.\n",
    "* To engineer more effective feature sets. For example, you can identify:\n",
    "    * Especially informative features.\n",
    "    * Redundant features.\n",
    "    * Features that vary so widely in scale that they may slow learning.\n",
    "    * Features with little or no unique predictive information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFDV\n",
    "\n",
    "TensorFlow Data Validation (TFDV) is a library for exploring and validating machine learning data. It is designed to be highly scalable and to work well with TensorFlow and TensorFlow Extended (TFX).\n",
    "\n",
    "**Tensorflow Data Validation (TFDV)** can analyze training and serving data and includes:\n",
    "\n",
    "- Computing descriptive statistics\n",
    "    - Scalable calculation of summary statistics of training and test data.\n",
    "    - Integration with a viewer for data distributions and statistics, as well as faceted comparison of pairs of features (Facets)\n",
    "\n",
    "- Inferring a schema\n",
    "    - Automated data-schema generation to describe expectations about data like required values, ranges, and vocabularies\n",
    "    - A schema viewer to help you inspect the schema.\n",
    "\n",
    "- Detecting data anomalies\n",
    "    - Perform validity checks by comparing data statistics against a schema that codifies expectations of the user.\n",
    "    - Detect training-serving skew by comparing examples in training and serving data.\n",
    "    - Detect data drift by looking at a series of data.\n",
    "    - An anomalies viewer so that you can see what features have anomalies and learn more in order to correct them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Libraries & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Librarires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import pkg_resources\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_data_validation as tfdv\n",
    "from tensorflow_data_validation import StatsOptions\n",
    "\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from apache_beam.options.pipeline_options import (\n",
    "    PipelineOptions,\n",
    "    GoogleCloudOptions,\n",
    "    StandardOptions,\n",
    "    SetupOptions,\n",
    "    WorkerOptions\n",
    ")\n",
    "\n",
    "from data_validation_utils import *\n",
    "\n",
    "print('INFO: TF version -- {}'.format(tf.__version__))\n",
    "print('INFO: TFDV version -- {}'.format(pkg_resources.get_distribution(\"tensorflow_data_validation\").version))\n",
    "print('INFO: Beam version -- {}'.format(pkg_resources.get_distribution(\"apache_beam\").version))\n",
    "print('INFO: Pyarrow version -- {}'.format(pkg_resources.get_distribution(\"pyarrow\").version))\n",
    "print('INFO: TFX-BSL version -- {}'.format(pkg_resources.get_distribution(\"tfx-bsl\").version))\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of input arguments for the data validation component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"irn-70656-dev-1307100302\"\n",
    "REGION = \"europe-west1\"\n",
    "RAW_DATA_PATH = \"gs://bike-sharing-data/\"\n",
    "BUCKET = \"bike-sharing-pipeline-metadata\"\n",
    "PIPELINE_VERSION = \"v0_1\"\n",
    "DATA_VERSION = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "RUNNER = \"DirectRunner\" # DirectRunner or DataflowRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['PIPELINE_VERSION'] = PIPELINE_VERSION\n",
    "os.environ['DATA_VERSION'] = DATA_VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Paths "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up some globals for the gcs files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up some globals for gcs file\n",
    "HANDLER = 'gs://' # ../ for local data, gs:// for cloud data\n",
    "    \n",
    "BASE_DIR = os.path.join(HANDLER, BUCKET, PIPELINE_VERSION)\n",
    "RUN_DIR = os.path.join(BASE_DIR, 'run', DATA_VERSION)\n",
    "\n",
    "STAGING_DIR = os.path.join(RUN_DIR, 'staging')\n",
    "OUTPUT_DIR = os.path.join(RUN_DIR, 'data_validation')\n",
    "\n",
    "FROZEN_STATS_PATH = os.path.join(BASE_DIR,'freeze', 'frozen_stats.txt')\n",
    "FROZEN_SCHEMA_PATH = os.path.join(BASE_DIR, 'freeze', 'frozen_schema.txt')\n",
    "DATA_STATS_PATH = os.path.join(OUTPUT_DIR, 'stats', 'data_stats.txt')\n",
    "DATA_SCHEMA_PATH = os.path.join(OUTPUT_DIR, 'schema', 'data_schema.txt')\n",
    "DATA_ANOMALIES_PATH = os.path.join(OUTPUT_DIR, 'anomalies', 'data_anomalies.txt')\n",
    "STATIC_HTML_PATH = os.path.join(OUTPUT_DIR, 'index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on Google Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up project and compute region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create GS bucket if not already created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if ! gsutil ls | grep -q gs://${BUCKET}/; then\n",
    "  gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally, TFDV uses Apache Beam's data-parallel processing framework to scale the computation of statistics over large datasets. \n",
    "\n",
    "To run TFDV on Google Cloud, the TFDV wheel file must be downloaded and provided to the Dataflow workers. We can download the wheel file to the current directory as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip download tensorflow_data_validation \\\n",
    "  --no-deps \\\n",
    "  --platform manylinux1_x86_64 \\\n",
    "  --only-binary=:all:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_WHL_FILE = [filename for filename in os.listdir('.') if filename.startswith('tensorflow_data_validation')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet shows an example usage of TFDV on Google Cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = 'datavalidation-' + re.sub(\"_\", \"-\", PIPELINE_VERSION) + \\\n",
    "    '-' + re.sub(\"_\", \"-\", DATA_VERSION)\n",
    "\n",
    "# Create and set your PipelineOptions.\n",
    "options = PipelineOptions()\n",
    "\n",
    "# For Cloud execution, set the Cloud Platform project, job_name,\n",
    "# staging location, temp_location and specify DataflowRunner.\n",
    "google_cloud_options = options.view_as(GoogleCloudOptions)\n",
    "google_cloud_options.project = PROJECT\n",
    "google_cloud_options.job_name = job_name\n",
    "google_cloud_options.region = REGION\n",
    "google_cloud_options.staging_location = STAGING_DIR\n",
    "google_cloud_options.temp_location = STAGING_DIR\n",
    "options.view_as(WorkerOptions).subnetwork = 'regions/{}/subnetworks/default'.format(REGION)\n",
    "setup_options = options.view_as(SetupOptions)\n",
    "# PATH_TO_WHL_FILE should point to the downloaded tfdv wheel file.\n",
    "setup_options.extra_packages = PATH_TO_WHL_FILE\n",
    "options.view_as(StandardOptions).runner = RUNNER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Computing descriptive data statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1- Computing descriptive statistics for current raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFDV can compute descriptive statistics that provide a quick overview of the data in terms of the features that are present and the shapes of their value distributions. Tools such as Facets Overview can provide a succinct visualization of these statistics for easy browsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_options = StatsOptions()\n",
    "stats_options.feature_whitelist = [\"datetime\",\"season\",\"weather\",\"daytype\",\"temp\",\n",
    "                                   \"atemp\",\"humidity\",\"windspeed\",\"casual\",\"registered\",\n",
    "                                   \"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating data statistics for initial dataset\n",
    "print('INFO: Generate & exporting data statistics to {}/'.format(DATA_STATS_PATH))\n",
    "data_stats =  tfdv.generate_statistics_from_csv(\n",
    "    data_location=os.path.join(RAW_DATA_PATH, 'train.csv'),\n",
    "    output_path=DATA_STATS_PATH,\n",
    "    pipeline_options=options,\n",
    "    stats_options=stats_options)                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2- Using Visualizations to Check Your Data\n",
    "\n",
    "TensorFlow Data Validation provides tools for visualizing the distribution of feature values. By examining these distributions in a Jupyter notebook using Facets you can catch common problems with data. **Visualizing statistics** with TFDV Facets allow us to:\n",
    "\n",
    "### 1.2.1- Identifying Suspicious Distributions\n",
    "\n",
    "#### Unbalanced Data\n",
    "\n",
    "An unbalanced feature is a feature for which one value predominates. Unbalanced features can occur naturally, but if a feature always has the same value you may have a data bug. To detect unbalanced features in a Facets Overview, choose \"Non-uniformity\" from the \"Sort by\" dropdown.\n",
    "\n",
    "In our case, no problem of unbalanced data.\n",
    "\n",
    "#### Uniformly Distributed Data\n",
    "\n",
    "A uniformly distributed feature is one for which all possible values appear with close to the same frequency. As with unbalanced data, this distribution can occur naturally, but can also be produced by data bugs.\n",
    "\n",
    "\n",
    "To detect uniformly distributed features in a Facets Overview, choose \"Non- uniformity\" from the \"Sort by\" dropdown and check the \"Reverse order\" checkbox:\n",
    "\n",
    "### 1.2.2- Missing Data\n",
    "\n",
    "To check whether a feature is missing values entirely:\n",
    "\n",
    "- Choose \"Amount missing/zero\" from the \"Sort by\" drop-down.\n",
    "- Check the \"Reverse order\" checkbox.\n",
    "- Look at the \"missing\" column to see the percentage of instances with missing values for a feature.\n",
    "\n",
    "A data bug can also cause incomplete feature values. For example you may expect a feature's value list to always have three elements and discover that sometimes it only has one. To check for incomplete values or other cases where feature value lists don't have the expected number of elements:\n",
    "\n",
    "Choose \"Value list length\" from the \"Chart to show\" drop-down menu on the right.\n",
    "\n",
    "Look at the chart to the right of each feature row. The chart shows the range of value list lengths for the feature. For example, the highlighted row in the screenshot below shows a feature that has some zero-length value lists:\n",
    "\n",
    "\n",
    "### 1.2.3- Large Differences in Scale Between Features\n",
    "\n",
    "If your features vary widely in scale, then the model may have difficulties learning. For example, if some features vary from 0 to 1 and others vary from 0 to 1,000,000,000, you have a big difference in scale. Compare the \"max\" and \"min\" columns across features to find widely varying scales.\n",
    "\n",
    "Consider normalizing feature values to reduce these wide variations.\n",
    "\n",
    "### 1.2.4- Labels with Invalid Labels\n",
    "\n",
    "TensorFlow's Estimators have restrictions on the type of data they accept as labels. For example, binary classifiers typically only work with {0, 1} labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdv.visualize_statistics(data_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Inferring a schema over the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema describes the expected properties of the data. Some of these properties are:\n",
    "\n",
    "- which features are expected to be present\n",
    "- their type\n",
    "- the number of values for a feature in each example\n",
    "- the presence of each feature across all examples\n",
    "- the expected domains of features.\n",
    "\n",
    "In short, the schema describes the expectations for \"correct\" data and can thus be used to detect errors in the data. \n",
    "\n",
    "Note that the schema is expected to be fairly static, e.g., several datasets can conform to the same schema, whereas statistics (described above) can vary per dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1- Inferring schema from data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFDV includes infer_schema() to generate a schema automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data set schema\n",
    "data_schema = tfdv.infer_schema(data_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfdv.display_schema(data_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2- Customizing schema\n",
    "\n",
    "In general, TFDV uses conservative heuristics to infer stable data properties from the statistics in order to avoid overfitting the schema to the specific dataset. It is strongly advised to review the inferred schema and refine it as needed, to capture any domain knowledge about the data that TFDV's heuristics might have missed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema itself is stored as a Schema protocol buffer and can thus be updated/edited using the standard protocol-buffer API. TFDV also provides a few utility methods to make these updates easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for feature in stats_options.feature_whitelist:\n",
    "#    tfdv.get_feature(data_schema, feature).value_count.min=1\n",
    "#    tfdv.get_feature(data_schema, feature).value_count.max=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3- Schema Environments\n",
    "\n",
    "By default, validations assume that all datasets in a pipeline adhere to a single schema. In some cases introducing slight schema variations is necessary, for instance features used as labels are required during training (and should be validated), but are missing during serving.\n",
    "\n",
    "Environments can be used to express such requirements. In particular, features in schema can be associated with a set of environments using `default_environment`, `in_environment` and `not_in_environment`.\n",
    "\n",
    "In our case, the feature named 'partRootRawLabels' is required for training, but is expected to be missing from serving. This can be expressed by:\n",
    "- Define two distinct environments in the schema: [\"SERVING\", \"TRAINING\"] and associate 'partRootRawLabels' only with environment \"TRAINING\".\n",
    "- Associate the training data with environment \"TRAINING\" and the serving data with environment \"SERVING\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# casual, registered, count should be required during training, optional while serving\n",
    "\n",
    "# All features are by default in both TRAINING and SERVING environments.\n",
    "# Specify that 'partRootLabels' feature is not in SERVING environment.\n",
    "data_schema.default_environment.append('TRAINING')\n",
    "data_schema.default_environment.append('SERVING')\n",
    "tfdv.get_feature(data_schema, 'casual').not_in_environment.append('SERVING')\n",
    "tfdv.get_feature(data_schema, 'registered').not_in_environment.append('SERVING')\n",
    "tfdv.get_feature(data_schema, 'count').not_in_environment.append('SERVING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4- Saving data schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    '''\n",
    "    A function that creates the directory of a provided path.\n",
    "    (Might not be needed to save results to GS)\n",
    "    '''\n",
    "    path_dir = re.search('(.*)/', path).group(1)\n",
    "    try:\n",
    "        os.mkdir(path_dir)\n",
    "    except OSError:\n",
    "        print (\"ERROR: Creation of the directory %s failed\" % path_dir)\n",
    "    else:\n",
    "        print (\"INFO: Successfully created the directory %s \" % path_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HANDLER != \"gs://\":\n",
    "    create_dir(DATA_SCHEMA_PATH) # for local use only\n",
    "    \n",
    "tfdv.write_schema_text(data_schema, DATA_SCHEMA_PATH)\n",
    "print('INFO: The data set schema was written to {}'.format(DATA_SCHEMA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5- Loading frozen schema/stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if frozen data schema exists otherwise create it from current data set\n",
    "try:\n",
    "    frozen_schema = tfdv.load_schema_text(input_path=FROZEN_SCHEMA_PATH)\n",
    "    print('INFO: Pipeline frozen data schema was loaded from {}'.format(FROZEN_SCHEMA_PATH))\n",
    "except:\n",
    "    # First pipeline run, create new schema\n",
    "    print('INFO: Frozen schema not found! First pipeline run! Saving current schema as frozen schema')\n",
    "    frozen_schema = data_schema\n",
    "    if HANDLER != \"gs://\":\n",
    "        create_dir(FROZEN_SCHEMA_PATH)\n",
    "    tfdv.write_schema_text(frozen_schema, FROZEN_SCHEMA_PATH)\n",
    "    print('INFO: A new pipeline data schema was written to {}'.format(FROZEN_SCHEMA_PATH))\n",
    "    \n",
    "# Check if frozen data statistics exist otherwise create them from current data set\n",
    "try:\n",
    "    frozen_stats = tfdv.load_statistics(FROZEN_STATS_PATH)\n",
    "    print('INFO: Pipeline frozen data statistics were loaded from {}'.format(FROZEN_STATS_PATH))\n",
    "except:\n",
    "    # First pipeline run, create new schema\n",
    "    print('INFO: No data statistics found at {}'.format(FROZEN_STATS_PATH))\n",
    "    print('INFO: Frozen data statistics not found! First pipeline run! Saving current data statistics as frozen data statistics')\n",
    "    frozen_stats=data_stats\n",
    "    # Save new pipeline data stats\n",
    "    tf.io.gfile.copy(\n",
    "        DATA_STATS_PATH,\n",
    "        FROZEN_STATS_PATH)\n",
    "    print('INFO: New pipeline data statistics were written to {}/'.format(FROZEN_STATS_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdv.display_schema(frozen_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Checking the data for errors\n",
    "\n",
    "## Matching the statistics of the dataset against a schema\n",
    "\n",
    "Given a schema, it is possible to check whether a dataset conforms to the expectations set in the schema. \n",
    "\n",
    "## Checking data skew and drift\n",
    "\n",
    "In addition to checking whether a dataset conforms to the expectations set in the schema, TFDV also provides functionalities to detect:\n",
    "\n",
    "- skew between training and serving data\n",
    "- drift between different days of data\n",
    "\n",
    "TFDV performs this check by comparing the statistics of different datasets based on the drift/skew comparators specified in the schema.\n",
    "\n",
    "Same with checking whether a dataset conform to the expectations set in the schema, the result is also an instance of the **Anomalies protocol buffer**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section we will:\n",
    "\n",
    "- Match data set statistics against frozen_schema\n",
    "- Check data drift between data statistics and previous frozen statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drift detection is supported for categorical features and between consecutive spans of data (i.e., between span N and span N+1), such as between different days of data. We express drift in terms of L-infinity distance, and you can set the threshold distance so that you receive warnings when the drift is higher than is acceptable. Setting the correct distance is typically an iterative process requiring domain knowledge and experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a drift comparator to schema for catagorical features and set the threshold to 0.01\n",
    "tfdv.get_feature(frozen_schema, 'season').drift_comparator.infinity_norm.threshold = 0.01\n",
    "tfdv.get_feature(frozen_schema, 'weather').drift_comparator.infinity_norm.threshold = 0.01\n",
    "tfdv.get_feature(frozen_schema, 'daytype').drift_comparator.infinity_norm.threshold = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect schema anomalies and drift on new data set\n",
    "print('INFO: Check for schema anomalies and drift on new data set.')\n",
    "data_anomalies = tfdv.validate_statistics(\n",
    "    statistics=data_stats,\n",
    "    schema = frozen_schema,\n",
    "    environment='TRAINING',\n",
    "    previous_statistics=frozen_stats)\n",
    "\n",
    "if HANDLER != \"gs://\":\n",
    "    create_dir(DATA_ANOMALIES_PATH) # for local use only\n",
    "tfdv.write_anomalies_text(data_anomalies, DATA_ANOMALIES_PATH)   \n",
    "print('INFO: Writing data anomalies to {}'.format(DATA_ANOMALIES_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdv.display_anomalies(data_anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4- Saving results for Kubeflow Artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The display functions of tfdv like `tfdv.display_schema` or `tfdv.visualize_statistics` allows us to visualize results regarding the schema, the statistics of our datasets, as well as the anomalies in a notebook. It would be interesting if we can visualize these results in the Pipelines UI.\n",
    "\n",
    "The Kubeflow Pipelines UI offers built-in support for several types of visualizations, which we can use for this purpose. An output artifact is an output emitted by a pipeline component, which the Kubeflow Pipelines UI understands and can render as rich visualizations. \n",
    "\n",
    "It’s useful for pipeline components to include artifacts so that you can provide for performance evaluation, quick decision making for the run, or comparison across different runs. Artifacts also make it possible to understand how the pipeline’s various components work. An artifact can range from a plain textual view of the data to rich interactive visualizations.\n",
    "\n",
    "To make use of this programmable UI, our pipeline component must write a JSON file to the component’s local filesystem. We can do this at any point during the pipeline execution.\n",
    "\n",
    "Available output viewers:\n",
    "* Confusion matrix \n",
    "* Markdown \n",
    "* ROC curve\n",
    "* Table\n",
    "* TensorBoard\n",
    "* Web app \n",
    "\n",
    "The web-app viewer provides flexibility for **rendering our custom tfdv output**. We can specify an HTML file that our component creates, and the Kubeflow Pipelines UI renders that HTML in the output page. \n",
    "\n",
    "We need to figure a way to render the output of the TFDV functions into an HTML code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions in the file `data_validation_utils` have been copied and modified to suit our desired output from the [github repo](https://github.com/tensorflow/data-validation/blob/v0.21.2/tensorflow_data_validation/utils/display_util.py) of tensorflow's `data-validation` open source project.\n",
    "\n",
    "* The function get_schema_html does the same as `tfdv.display_schema` but the output is rendered as HTML tables instead of dataframes.\n",
    "* `get_statistics_html` and `get_anomalies_html` were already used by tfdv as intermediary functions but aren't directly exposed by the library. We can hence keep a copy of this particular version of the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('INFO: Rendering HTML artifacts.')\n",
    "features_html, domains_html = get_schema_html(data_schema)\n",
    "data_stats_drift_html = get_statistics_html(data_stats, frozen_stats, lhs_name=\"NEW_DATA\", rhs_name=\"PREV_PREV\")\n",
    "data_anomalies_html = get_anomalies_html(data_anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add some style to our html page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style=\"\"\"\n",
    "<style>\n",
    "h1 {\n",
    "    color:#0B6FA4;\n",
    "}\n",
    "h2 {\n",
    "  color:#0B6FA4;\n",
    "}\n",
    "table.paleBlueRows {\n",
    "    font-family: Arial, Helvetica, sans-serif;\n",
    "    border: 1px solid #FFFFFF;\n",
    "    text-align: left;\n",
    "    border-collapse: collapse;\n",
    "}\n",
    "table.paleBlueRows td, table.paleBlueRows th {\n",
    "    border: 1px solid #FFFFFF;\n",
    "    padding: 3px 2px;\n",
    "}\n",
    "table.paleBlueRows tbody td {\n",
    "    font-size: 13px;\n",
    "}\n",
    "table.paleBlueRows tr:nth-child(even) {\n",
    "    background: #D0E4F5;\n",
    "}\n",
    "table.paleBlueRows thead {\n",
    "    background: #0B6FA4;\n",
    "    background: -moz-linear-gradient(top, #4893bb 0%, #237dad 66%, #0B6FA4 100%);\n",
    "    background: -webkit-linear-gradient(top, #4893bb 0%, #237dad 66%, #0B6FA4 100%);\n",
    "    background: linear-gradient(to bottom, #4893bb 0%, #237dad 66%, #0B6FA4 100%);\n",
    "    border-bottom: 5px solid #FFFFFF;\n",
    "}\n",
    "table.paleBlueRows thead th {\n",
    "    font-size: 15px;\n",
    "    font-weight: bold;\n",
    "    color: #FFFFFF;\n",
    "    text-align: left;\n",
    "    border-left: 2px solid #FFFFFF;\n",
    "}\n",
    "table.paleBlueRows thead th:first-child {\n",
    "    border-left: none;\n",
    "}\n",
    "\n",
    "table.paleBlueRows tfoot td {\n",
    "    font-size: 14px;\n",
    "}\n",
    "</style>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the different html outputs to one html page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = style +  '<h1>Schema</h1><h2>Features</h2>'  + features_html  + '<br><h2>Domains</h2>' + domains_html + \\\n",
    "'<br><h1>Dataset Statistics</h1>' +  data_stats_drift_html + \\\n",
    "'<br><h1>Dataset Anomalies</h1>' +  data_anomalies_html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a HTML file to the component’s local filesystem and upload HTML file to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and upload HTML file to GCS\n",
    "OUTPUT_FILE_PATH = './index.html'\n",
    "    \n",
    "with open(OUTPUT_FILE_PATH, \"wb\") as f:\n",
    "    f.write(html.encode('utf-8'))\n",
    "    \n",
    "tf.io.gfile.copy(\n",
    "    OUTPUT_FILE_PATH,\n",
    "    STATIC_HTML_PATH,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our pipeline component must write a JSON file to the component’s local filesystem. We can do this at any point during the pipeline execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "'outputs' : [{\n",
    "  'type': 'web-app',\n",
    "  'storage': 'gcs',\n",
    "  'source': STATIC_HTML_PATH,\n",
    "}]\n",
    "}\n",
    "\n",
    "# Write output files for next steps in pipeline\n",
    "with file_io.FileIO('./mlpipeline-ui-metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write data_version to txt output file to be used for next steps inputs in pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with file_io.FileIO('./data_version.txt', 'w') as f:\n",
    "    f.write(DATA_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DATA_VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view our final html file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- Freeze the new schema\n",
    "\n",
    "In deploy component, only if model is deployed"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
