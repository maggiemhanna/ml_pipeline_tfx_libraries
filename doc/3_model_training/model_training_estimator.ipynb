{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Libraries & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Librarires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import pkg_resources\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow_model_analysis as tfma\n",
    "\n",
    "\n",
    "print('INFO: TF version -- {}'.format(tf.__version__))\n",
    "print('INFO: TFT version -- {}'.format(pkg_resources.get_distribution(\"tensorflow_transform\").version))\n",
    "print('INFO: TFMA version -- {}'.format(pkg_resources.get_distribution(\"tensorflow_model_analysis\").version))\n",
    "print('INFO: Beam version -- {}'.format(pkg_resources.get_distribution(\"apache_beam\").version))\n",
    "print('INFO: Pyarrow version -- {}'.format(pkg_resources.get_distribution(\"pyarrow\").version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of input arguments for the data validation component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"irn-70656-dev-1307100302\"\n",
    "REGION = 'europe-west1'\n",
    "BUCKET = \"bike-sharing-pipeline-metadata\"\n",
    "PIPELINE_VERSION = \"v0_1\"\n",
    "DATA_VERSION = \"200909_154702\"\n",
    "MODEL_VERSION = datetime.now().strftime('%y%m%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features, labels, and key columns\n",
    "NUMERIC_FEATURE_KEYS=[\"temp\", \"atemp\", \"humidity\", \"windspeed\"] \n",
    "CATEGORICAL_FEATURE_KEYS=[\"season\", \"weather\", \"daytype\"] \n",
    "KEY_COLUMN = \"datetime\"\n",
    "LABEL_COLUMN = \"count\"\n",
    "\n",
    "def transformed_name(key):\n",
    "    return key "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Paths "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up some globals for the gcs files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up some globals for gcs file\n",
    "HANDLER = 'gs://' # ../ for local data, gs:// for cloud data\n",
    "\n",
    "BASE_DIR = HANDLER + BUCKET+'/'+PIPELINE_VERSION\n",
    "RUN_DIR = BASE_DIR+'/run/'+DATA_VERSION\n",
    "DATA_DIR = RUN_DIR+'/data_transform'\n",
    "OUTPUT_DIR = RUN_DIR+'/model_training/' + MODEL_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['PIPELINE_VERSION'] = PIPELINE_VERSION\n",
    "os.environ['DATA_DIR'] = DATA_DIR\n",
    "os.environ['OUTPUT_DIR'] = OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up GCP project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluate input functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate input functions\n",
    "    \n",
    "def input_fn(data_path, label_column, tf_transform_output, batch_size, mode = tf.estimator.ModeKeys.TRAIN):\n",
    "    \"\"\"Create an input function reading TFRecord files using the data API.\n",
    "    Args:\n",
    "        data_path: path of the data in tfrecords format\n",
    "        mode: tf estimator mode key\n",
    "        batch_size: number of observations in batch\n",
    "\n",
    "    Returns:\n",
    "        input_fn: data input function\n",
    "    \"\"\"\n",
    "    \n",
    "    features_spec = tf_transform_output.transformed_feature_spec()\n",
    "\n",
    "    def _input_fn():\n",
    "        # Create list of files in the data path\n",
    "        file_list = tf.io.gfile.glob(data_path)\n",
    "\n",
    "        # Create dataset from file list\n",
    "        dataset = tf.data.TFRecordDataset(filenames=file_list, compression_type = \"GZIP\", num_parallel_reads=5)\n",
    "        def parse_example(example):\n",
    "            parsed_features = tf.io.parse_single_example(example, features_spec)\n",
    "            label = parsed_features.pop(label_column)\n",
    "            return parsed_features, label\n",
    "          \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            num_epochs = None # indefinitely, we'll set this in train spec\n",
    "            dataset = dataset.shuffle(buffer_size=10*batch_size)\n",
    "        else:\n",
    "            num_epochs = 1 # end-of-input after one epoch\n",
    "\n",
    "        dataset = dataset.repeat(num_epochs)\n",
    "        dataset = dataset.map(parse_example, num_parallel_calls=5)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.prefetch(buffer_size=1)\n",
    "     \n",
    "        return dataset\n",
    "    \n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_columns(tf_transform_output):\n",
    "    \n",
    "    numeric_columns = [\n",
    "      tf.feature_column.numeric_column(transformed_name(key))\n",
    "      for key in NUMERIC_FEATURE_KEYS\n",
    "    ]\n",
    "    \n",
    "    categorical_columns = [\n",
    "      tf.feature_column.categorical_column_with_vocabulary_file(\n",
    "        transformed_name(key), \n",
    "        vocabulary_file=tf_transform_output.vocabulary_file_by_name(\n",
    "            vocab_filename=key), \n",
    "        dtype=tf.dtypes.string,\n",
    "        default_value=None, \n",
    "        num_oov_buckets=0)\n",
    "      for key in CATEGORICAL_FEATURE_KEYS\n",
    "    ]\n",
    "    \n",
    "    indicator_columns = [\n",
    "      tf.feature_column.indicator_column(categorical_column)\n",
    "      for categorical_column in categorical_columns\n",
    "    ]\n",
    "       \n",
    "    feature_columns = numeric_columns + indicator_columns\n",
    "\n",
    "    return feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Custom Estimator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(labels, predictions):\n",
    "    pred_values = predictions['predictions']\n",
    "    rmse = tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")\n",
    "    rmse.update_state(y_true=labels, y_pred=pred_values)\n",
    "    return {'rmse': rmse}\n",
    "\n",
    "def rmse_2(labels, predictions):\n",
    "    pred_values = predictions['predictions']\n",
    "    rmse = tf.compat.v1.metrics.root_mean_squared_error(labels, pred_values)\n",
    "    return {'rmse': rmse}\n",
    "\n",
    "\n",
    "def mae(labels, predictions):\n",
    "    pred_values = tf.squeeze(input = predictions[\"predictions\"], axis = -1)\n",
    "    mae = tf.keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "    mae.update_state(y_true=labels, y_pred=pred_values)\n",
    "    return {'mae': mae}\n",
    "\n",
    "\n",
    "def create_estimator_model(output_dir, feature_columns, hidden_units, run_config):\n",
    "    model = tf.estimator.DNNRegressor(\n",
    "        model_dir = output_dir,\n",
    "        feature_columns = feature_columns,\n",
    "        hidden_units = hidden_units, # specify neural architecture\n",
    "        config = run_config\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving input function\n",
    "\n",
    "Note that we use our create_feature_keras_input function again so that we perform our feature engineering during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn(tf_transform_output, label_column):\n",
    "    \"\"\"Creates an input function reading from raw data.\n",
    "\n",
    "    Args:\n",
    "    tf_transform_output: Wrapper around output of tf.Transform.\n",
    "\n",
    "    Returns:\n",
    "    The serving input function.\n",
    "    \"\"\"\n",
    "    raw_feature_spec = tf_transform_output.raw_feature_spec()\n",
    "    # Remove label since it is not available during serving.\n",
    "    raw_feature_spec.pop(label_column)\n",
    "\n",
    "    def _input_fn():\n",
    "        \"\"\"Input function for serving.\"\"\"\n",
    "        # Get raw features by generating the basic serving input_fn and calling it.\n",
    "        # Here we generate an input_fn that expects a parsed Example proto to be fed\n",
    "        # to the model at serving time.  See also\n",
    "        # tf.estimator.export.build_raw_serving_input_receiver_fn.\n",
    "        raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
    "            raw_feature_spec, default_batch_size=None)\n",
    "        serving_input_receiver = raw_input_fn()\n",
    "\n",
    "        # Apply the transform function that was used to generate the materialized\n",
    "        # data.\n",
    "        raw_features = serving_input_receiver.features\n",
    "        transformed_features = tf_transform_output.transform_raw_features(\n",
    "            raw_features)\n",
    "\n",
    "        return tf.estimator.export.ServingInputReceiver(\n",
    "            transformed_features, serving_input_receiver.receiver_tensors)\n",
    "\n",
    "    return _input_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval input function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export EvalSavedModel using TFMA\n",
    "\n",
    "In order to setup TensorFlow Model Analysis, an EvalSavedModel needs to be exported during training, which is a special SavedModel containing annotations for the metrics, features, labels, and so on in your model. TensorFlow Model Analysis uses this EvalSavedModel to compute metrics.\n",
    "\n",
    "As part of this, we will have to provide a special eval_input_receiver_fn, analogous to the serving_input_receiver_fn, which will extract the features and labels from the input data. As with serving_input_receiver_fn, we have utility functions to help us with this. \n",
    "\n",
    "Like serving_input_receiver_fn, the eval_input_receiver_fn function defines an input placeholder example, parses the features from the example, and returns the parsed features. It parses and returns the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input_receiver_fn(tf_transform_output, label_column):\n",
    "    \"\"\"Function that defines an input placeholder,\n",
    "     parses and returns features and labels for evaluation.\"\"\"\n",
    "    \n",
    "    def _input_fn():\n",
    "\n",
    "        serialized_tf_example = tf.compat.v1.placeholder(\n",
    "            dtype=tf.string, shape=[None], name='input_example_placeholder')\n",
    "\n",
    "        # This *must* be a dictionary containing a single key 'examples', which\n",
    "        # points to the input placeholder.\n",
    "        receiver_tensors = {'examples': serialized_tf_example}\n",
    "\n",
    "        transformed_feature_spec = tf_transform_output.transformed_feature_spec()\n",
    "             \n",
    "        features = tf.io.parse_example(serialized_tf_example, transformed_feature_spec)\n",
    "\n",
    "        return tfma.export.EvalInputReceiver(\n",
    "            features=features,\n",
    "            receiver_tensors=receiver_tensors,\n",
    "            labels=features[label_column])\n",
    "\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluate\n",
    "\n",
    "To train our model, we can use train_and_evaluate. Note that we use tf.keras.estimator.model_to_estimator to create our estimator. It takes as arguments the compiled keras model, the OUTDIR, and optionally a tf.estimator.Runconfig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_size(file_path):\n",
    "    \"\"\"Function that fetchs the size of the Tfrecords dataset.\"\"\"\n",
    "    size = 1\n",
    "    file_list = tf.io.gfile.glob(file_path)\n",
    "    for file in file_list:\n",
    "        for record in tf.compat.v1.io.tf_record_iterator(file, options=tf.io.TFRecordOptions(\n",
    "    compression_type='GZIP')):\n",
    "            size += 1\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_session_config_from_env_var():\n",
    "    \"\"\"Returns a tf.ConfigProto instance that has appropriate device_filters\n",
    "    set.\"\"\"\n",
    "\n",
    "    tf_config = json.loads(os.environ.get('TF_CONFIG', '{}'))\n",
    "\n",
    "    # Master should only communicate with itself and ps\n",
    "    if (tf_config and 'task' in tf_config and 'type' in tf_config[\n",
    "            'task'] and 'index' in tf_config['task']):\n",
    "        if tf_config['task']['type'] == 'master':\n",
    "            return tf.ConfigProto(device_filters=['/job:ps', '/job:master'])\n",
    "        # Worker should only communicate with itself and ps\n",
    "        elif tf_config['task']['type'] == 'worker':\n",
    "            return tf.ConfigProto(device_filters=[\n",
    "                '/job:ps',\n",
    "                '/job:worker/task:%d' % tf_config['task']['index']\n",
    "            ])\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(params):\n",
    "    \n",
    "    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO) # so loss is printed during training\n",
    "    \n",
    "    # Extract params from task.py\n",
    "    DATA_DIR = params[\"data_dir\"]\n",
    "    OUTPUT_DIR = params[\"output_dir\"]\n",
    "    HIDDEN_UNITS_1 = params[\"hidden_units_1\"]\n",
    "    HIDDEN_UNITS_2 = params[\"hidden_units_2\"]\n",
    "    HIDDEN_UNITS_3 = params[\"hidden_units_3\"]\n",
    "    BATCH_SIZE = params[\"batch_size\"]\n",
    "    NUM_EPOCHS = params[\"num_epochs\"]\n",
    "    LEARNING_RATE = params[\"learning_rate\"]\n",
    "    \n",
    "    # Setting up paths \n",
    "    TRAIN_PATH = DATA_DIR+'/train*'\n",
    "    VAL_PATH = DATA_DIR+'/val*'\n",
    "    TEST_PATH = DATA_DIR+'/test*'\n",
    "\n",
    "    # Define key and label columns\n",
    "    KEY_COLUMN = 'datetime'\n",
    "    LABEL_COLUMN = 'count'\n",
    "    \n",
    "    # Training set size\n",
    "    TRAIN_SIZE = get_dataset_size(TRAIN_PATH)\n",
    "\n",
    "    NUM_STEPS = TRAIN_SIZE / BATCH_SIZE * NUM_EPOCHS # total steps for which to train model\n",
    "    CHECKPOINTS_STEPS = 16 # checkpoint every N steps\n",
    "    \n",
    "    tf_transform_output = tft.TFTransformOutput(os.path.join(DATA_DIR, 'tft_output'))\n",
    "\n",
    "    FEATURE_COLUMNS = create_feature_columns(tf_transform_output)\n",
    "    \n",
    "    run_config = tf.estimator.RunConfig(\n",
    "        tf_random_seed = 1, # for reproducibility\n",
    "        save_checkpoints_steps = CHECKPOINTS_STEPS, # checkpoint every N steps\n",
    "        save_summary_steps = int(CHECKPOINTS_STEPS/5),\n",
    "        session_config = _get_session_config_from_env_var()\n",
    "        )\n",
    "    \n",
    "    estimator = create_estimator_model(OUTPUT_DIR, FEATURE_COLUMNS, [HIDDEN_UNITS_1, \n",
    "                                       HIDDEN_UNITS_2, HIDDEN_UNITS_3], run_config)\n",
    "    \n",
    "    estimator = tf.estimator.add_metrics(estimator = estimator, metric_fn = rmse) \n",
    "    estimator = tf.estimator.add_metrics(estimator = estimator, metric_fn = mae) \n",
    "\n",
    "    train_input_fn = input_fn(TRAIN_PATH, LABEL_COLUMN, tf_transform_output, \n",
    "                              BATCH_SIZE, tf.estimator.ModeKeys.TRAIN)\n",
    "    val_input_fn = input_fn(VAL_PATH, LABEL_COLUMN, tf_transform_output, \n",
    "                            BATCH_SIZE, tf.estimator.ModeKeys.EVAL)\n",
    "    \n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn = train_input_fn,\n",
    "        max_steps = NUM_STEPS)\n",
    "\n",
    "    exporter = tf.estimator.LatestExporter(name = 'exporter', \n",
    "               serving_input_receiver_fn = serving_input_fn(tf_transform_output, LABEL_COLUMN))\n",
    "\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn = val_input_fn,\n",
    "        steps = CHECKPOINTS_STEPS, # Number of steps to run evalution for at each checkpoint\n",
    "        start_delay_secs = 1, # wait at least N seconds before first evaluation (default 120)\n",
    "        throttle_secs = 16, # wait at least N seconds before each subsequent evaluation (default 600)\n",
    "        exporters = exporter) # export SavedModel once at the end of training\n",
    "    \n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator = estimator, \n",
    "        train_spec = train_spec, \n",
    "        eval_spec = eval_spec) \n",
    "    \n",
    "    # Also export the EvalSavedModel\n",
    "    tfma.export.export_eval_savedmodel(\n",
    "        estimator=estimator, export_dir_base=OUTPUT_DIR + '/eval_saved_model/',\n",
    "        eval_input_receiver_fn=eval_input_receiver_fn(tf_transform_output, LABEL_COLUMN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run train and evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"data_dir\": DATA_DIR,\n",
    "    \"output_dir\": OUTPUT_DIR,\n",
    "    \"hidden_units_1\": 8,\n",
    "    \"hidden_units_2\": 16,\n",
    "    \"hidden_units_3\": 8,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_epochs\": 1,\n",
    "    \"learning_rate\": 0.001,\n",
    "\n",
    "}\n",
    "train_and_evaluate(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir $OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MODEL_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
