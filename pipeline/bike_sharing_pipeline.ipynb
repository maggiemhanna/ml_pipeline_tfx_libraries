{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "* Create a Kubeflow pipeline\n",
    "* Use container images from container registry to train and deploy the model in the pipeline\n",
    "* Submit a job for execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "\n",
    "# Install the SDK (Uncomment the code if the SDK is not installed before)\n",
    "#!pip3 install --upgrade pip -q\n",
    "#!pip3 install kfp --upgrade -q\n",
    "#!pip3 install pandas --upgrade -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import subprocess\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "#import pandas as pd\n",
    "import kfp\n",
    "import kfp.compiler as compiler\n",
    "import kfp.components as comp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.gcp as gcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mDEPRECATION: The default format will switch to columns in the future. You can use --format=(legacy|columns) (or define a format=(legacy|columns) in your pip.conf under the [list] section) to disable this warning.\u001b[0m\n",
      "kfp (0.1.34)\n",
      "kfp-server-api (0.1.18.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep kfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "PROJECT = 'irn-70656-dev-1307100302' # project Id\n",
    "REGION = 'europe-west1' # region\n",
    "RAW_DATA_PATH = 'gs://bike-sharing-data/' # data collection repo\n",
    "BUCKET = 'bike-sharing-pipeline-metadata' # ML workflow bucket\n",
    "BUCKET_STAGING = 'bike-sharing-pipeline-staging' # ML workflow bucket\n",
    "PIPELINE_VERSION = 'v0_1'\n",
    "\n",
    "RUNNER_VALIDATION = 'DirectRunner'\n",
    "RUNNER_TRANSFORM = 'DirectRunner'\n",
    "RUNNER_TRAINING = 'AIplatformRunner'\n",
    "RUNNER_ANALYSIS = 'DirectRunner'\n",
    "\n",
    "# GCR docker images\n",
    "SIN_VALIDATION = '7dda19c36262c082e9d58e53af19122949ff937c3ce61ddf5034c224026564e2' # data validation docker image\n",
    "SIN_TRANSFORM = '5862b073f520d5de4966f4614e37de58210eb1a3857d3838b7b2461bb27fcec6' # data transform docker image\n",
    "SIN_TRAINING = '83e77710ff8ee176166d59db25c19f100612171fa9b9a13275b951f80a6d7740' # model training docker image\n",
    "SIN_ANALYSIS = 'bdd30638ea1327addec245fbcb995973f8da2f3783134b434d0940c8f9ba1210' # model analysis docker image\n",
    "SIN_DEPLOYMENT = '84de4a40f6aecde5d9315576a44007fd4ecbd315c3626c97b551fe0c09563387' # model deployment docker image\n",
    "\n",
    "# Pipeline metadata\n",
    "PIPELINE_NAME = 'Bike Sharing Demand Prediction'\n",
    "PIPELINE_FILENAME_SUFFIX = 'bikesharing_demand'\n",
    "PIPELINE_DESCRIPTION = 'Pipeline that runs the full ML cycle for Bike Sharing Demand Predictions.'\n",
    "EXPERIMENT_NAME = ('Bike_Sharing_Demand_Prediction'+'__' + PIPELINE_VERSION).upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDict(dict):\n",
    "    def __getattr__(self, name):\n",
    "        if name in self:\n",
    "            return self[name]\n",
    "        else:\n",
    "            raise AttributeError(\"No such attribute: \" + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=PIPELINE_NAME,\n",
    "    description=PIPELINE_DESCRIPTION\n",
    ")    \n",
    "def pipeline(\n",
    "    project=dsl.PipelineParam(name='project', value=PROJECT),\n",
    "    region=dsl.PipelineParam(name='region', value=REGION),\n",
    "    raw_data_path=dsl.PipelineParam(name='raw_data_path', value=RAW_DATA_PATH),\n",
    "    bucket=dsl.PipelineParam(name='bucket', value=BUCKET),\n",
    "    bucket_staging=dsl.PipelineParam(name='bucket_staging', value=BUCKET_STAGING),\n",
    "    pipeline_version=dsl.PipelineParam(name='pipeline_version', value=PIPELINE_VERSION),\n",
    "    runner_validation=dsl.PipelineParam(name='runner_validation', value=RUNNER_VALIDATION),\n",
    "    runner_transform=dsl.PipelineParam(name='runner_transform', value=RUNNER_TRANSFORM),\n",
    "    runner_training=dsl.PipelineParam(name='runner_training', value=RUNNER_TRAINING),\n",
    "    runner_analysis=dsl.PipelineParam(name='runner_analysis', value=RUNNER_ANALYSIS),\n",
    "    sin_validation=dsl.PipelineParam(name='sin_validation', value=SIN_VALIDATION),\n",
    "    sin_transform=dsl.PipelineParam(name='sin_transform', value=SIN_TRANSFORM),\n",
    "    sin_training=dsl.PipelineParam(name='sin_training', value=SIN_TRAINING),\n",
    "    sin_analysis=dsl.PipelineParam(name='sin_analysis', value=SIN_ANALYSIS),\n",
    "    sin_deployment=dsl.PipelineParam(name='sin_deployment', value=SIN_DEPLOYMENT),\n",
    "    last_data_version='200911_154731',\n",
    "    last_model_version='200911_154828',\n",
    "    last_trial_id='1',\n",
    "    last_deployment_flag='OK'\n",
    "):\n",
    "    \n",
    "\n",
    "    start_step = 1\n",
    "        \n",
    "    # Step 1: Validate source data\n",
    "    if start_step <= 1:\n",
    "        validation = dsl.ContainerOp(\n",
    "            name='data-validation',\n",
    "            image='eu.gcr.io/irn-70656-dev-1307100302/bikesharing-data-validation@sha256:'+str(sin_validation),\n",
    "            arguments=[\n",
    "                project,\n",
    "                region,\n",
    "                raw_data_path, \n",
    "                bucket,\n",
    "                pipeline_version,\n",
    "                runner_validation\n",
    "            ],\n",
    "            file_outputs={'data_version': '/data_version.txt',\n",
    "                          'mlpipeline_ui_metadata': '/mlpipeline-ui-metadata.json'}\n",
    "        ).apply(gcp.use_gcp_secret('user-gcp-sa'))\n",
    "    else:\n",
    "        validation = ObjectDict({\n",
    "            'outputs': {\n",
    "                'data_version': last_data_version\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Step 2: Create ML datasets\n",
    "    if start_step <= 2:\n",
    "        transform = dsl.ContainerOp(\n",
    "            name='data-transform',\n",
    "            image='eu.gcr.io/irn-70656-dev-1307100302/bikesharing-data-transform@sha256:'+str(sin_transform),\n",
    "            arguments=[\n",
    "                '--pipeline_version', project,\n",
    "                '--region', region,\n",
    "                '--raw_data_path', raw_data_path, \n",
    "                '--bucket', bucket,\n",
    "                '--pipeline_version', pipeline_version,\n",
    "                '--data_version', validation.outputs['data_version'],\n",
    "                '--runner', runner_transform\n",
    "            ],\n",
    "            file_outputs={'data_version': '/data_version.txt'}\n",
    "        ).apply(gcp.use_gcp_secret('user-gcp-sa'))\n",
    "    else:\n",
    "        transform = ObjectDict({\n",
    "            'outputs': {\n",
    "                'data_version': last_data_version\n",
    "            }\n",
    "        })   \n",
    "        \n",
    "  \n",
    "    # Step 3: Train model\n",
    "    if start_step <= 3:\n",
    "        training = dsl.ContainerOp(\n",
    "            name='model-training',\n",
    "            image='eu.gcr.io/irn-70656-dev-1307100302/bikesharing-model-training@sha256:'+str(sin_training),\n",
    "            arguments=[\n",
    "                project,\n",
    "                region,\n",
    "                bucket,\n",
    "                bucket_staging,\n",
    "                pipeline_version,\n",
    "                transform.outputs['data_version'],\n",
    "                runner_training\n",
    "            ],\n",
    "            file_outputs={\n",
    "                          'data_version': '/data_version.txt',\n",
    "                          'model_version': '/model_version.txt',\n",
    "                          'trial_id': '/trial_id.txt',\n",
    "                         }\n",
    "        ).apply(gcp.use_gcp_secret('user-gcp-sa'))\n",
    "    else:\n",
    "        training = ObjectDict({\n",
    "            'outputs': {\n",
    "                'data_version': last_data_version,\n",
    "                'model_version': last_model_version,\n",
    "                'trial_id': last_trial_id\n",
    "            }\n",
    "        }) \n",
    "    # Step 4: Analyze model\n",
    "    if start_step <= 4:\n",
    "        analysis = dsl.ContainerOp(\n",
    "            name='model-analysis',\n",
    "            image='eu.gcr.io/irn-70656-dev-1307100302/bikesharing-model-analysis@sha256:'+str(sin_analysis),\n",
    "            arguments=[\n",
    "                '--pipeline_version', project,\n",
    "                '--region', region,\n",
    "                '--bucket', bucket,\n",
    "                '--pipeline_version', pipeline_version,\n",
    "                '--data_version', training.outputs['data_version'],\n",
    "                '--model_version', training.outputs['model_version'],\n",
    "                '--trial_id', training.outputs['trial_id'],\n",
    "                '--runner', runner_analysis\n",
    "            ],\n",
    "            file_outputs={'data_version': '/data_version.txt',\n",
    "                          'model_version': '/model_version.txt',\n",
    "                          'trial_id': '/trial_id.txt',\n",
    "                          'deployment_flag': '/deployment_flag.txt',\n",
    "                          'mlpipeline_ui_metadata': '/mlpipeline-ui-metadata.json'}\n",
    "        ).apply(gcp.use_gcp_secret('user-gcp-sa'))\n",
    "    else:\n",
    "        analysis = ObjectDict({\n",
    "            'outputs': {\n",
    "                'data_version': last_data_version,\n",
    "                'model_version': last_model_version,\n",
    "                'trial_id': last_trial_id,\n",
    "                'deployment_flag': last_deployment_flag,\n",
    "            }\n",
    "        })\n",
    "        \n",
    "    # Step 5: Deploy model\n",
    "    if start_step <= 5:\n",
    "        deployment = dsl.ContainerOp(\n",
    "            name='model-deployment',\n",
    "            image='eu.gcr.io/irn-70656-dev-1307100302/bikesharing-model-deployment@sha256:'+str(sin_deployment),\n",
    "            arguments=[\n",
    "                project,\n",
    "                region,\n",
    "                bucket,\n",
    "                pipeline_version,\n",
    "                analysis.outputs['data_version'],\n",
    "                analysis.outputs['model_version'],\n",
    "                analysis.outputs['trial_id'],\n",
    "                analysis.outputs['deployment_flag']\n",
    "            ]\n",
    "        ).apply(gcp.use_gcp_secret('user-gcp-sa'))       \n",
    "\n",
    "# Reference for invocation later\n",
    "pipeline_func = pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/kfp/dsl/_metadata.py:118: UserWarning: Explicit creation of `kfp.dsl.PipelineParam`s by the users is deprecated. The users should define the parameter type and default values using standard pythonic constructs: def my_func(a: int = 1, b: str = \"default\"):\n",
      "  warnings.warn('Explicit creation of `kfp.dsl.PipelineParam`s by the users is deprecated. The users should define the parameter type and default values using standard pythonic constructs: def my_func(a: int = 1, b: str = \"default\"):')\n"
     ]
    }
   ],
   "source": [
    "pipeline_filename = 'pipeline_' + PIPELINE_FILENAME_SUFFIX + '_' + PIPELINE_VERSION + '.tar.gz'\n",
    "\n",
    "compiler.Compiler().compile(pipeline_func, pipeline_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the pipeline for execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/250e3735-5d7d-4649-a6b9-dda00a0b1631\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Specify pipeline argument values\n",
    "arguments = {}\n",
    "\n",
    "# Get or create an experiment and submit a pipeline run\n",
    "client = kfp.Client()\n",
    "try:\n",
    "    experiment = client.get_experiment(experiment_name=EXPERIMENT_NAME)\n",
    "except:\n",
    "    experiment = client.create_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# Submit a pipeline run\n",
    "run_name = pipeline_func.__name__ + '_run_' + datetime.now(timezone.utc).strftime(\"%y%m%d_%H%M%S\")\n",
    "run_result = client.run_pipeline(experiment.id, run_name, pipeline_filename, arguments)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
